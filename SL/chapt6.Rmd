---
title: "chapt6"
author: "yz"
date: "4 April 2019"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.

```{r}
library(ISLR)
summary(Hitters)
```

Eradicate the NA values in Hitters

```{r}
Hitters <- na.omit(Hitters)
with(Hitters, sum(is.na(Salary)))
```

Best subset regression
----------------------

Use function regsubsets from the library leaps to do subset regression

```{r}
library(leaps)
regfit.full <- regsubsets(Salary~., data=Hitters)
summary(regfit.full)
```

Deafult best-subsets up to size 8; use nvmax to change the maximal size

```{r}
regfit.full <- regsubsets(Salary~., data=Hitters, nvmax=19)
reg.summary <- summary(regfit.full)
names(reg.summary)
which.min(reg.summary$cp)
plot(reg.summary$cp, xlab="number of variables", ylab="cp") + points(10, reg.summary$cp[10], pch=20, col="red")
```

Use the plot function with option scale="Cp" for 'regsubsets' object
```{r}
plot(regfit.full, scale="Cp")
coef(regfit.full, 10)
```

Forward stepwise selection
---------------------------
Using forward stepwise selection by using the function `regsubsets` and specifing `method = "forward"`

```{r}
regfit.fwd <- regsubsets(Salary~., data=Hitters, nvmax=19, method="forward")
regfit.bkd <- regsubsets(Salary~., data=Hitters, nvmax=19, method="backward")
summary(regfit.fwd)
summary(regfit.bkd)
names(regfit.fwd)
plot(regfit.fwd, scale="Cp")
```

Model Selection Using a Validation Set
---------------------------------------

Divide the dataset into training and validation set. Regress the model using the training dataset 

```{r}
dim(Hitters)
set.seed(1)
train <- sample(seq(263), 180, replace=FALSE)
regfit.fwd <- regsubsets(Salary~., data=Hitters[train,], nvmax=19, method="forward")
```

Calculate the mean sqaured error between predicted and true value (training dataset) and select
the model with the lowest RMSE
```{r}
val.errors <- rep(NA, 19)
x.test <- model.matrix(Salary~., data=Hitters[-train,])
for(i in 1:19){
        coefi <- coef(regfit.fwd, id=i)
        pred <- x.test[,names(coefi)]%*%coefi
        val.errors[i] <- mean((Hitters$Salary[-train]-pred)^2)
}
plot(sqrt(val.errors), ylab="RMSE", ylim=c(300,400), pch=19, type="b") + points(sqrt(regfit.fwd$rss[-1]/180), col="blue", pch=19, type="b") + legend("topright", legend=c("g","Validation"), col=c("blue","black"), pch=19)
```

Write a function predict method function to save time
```{r}
predict.regsubsets <- function(object, newdata, id,...){
        form <- as.formula(object$call[[2]])
        mat <- model.matrix(form, newdata)
        coefi <- coef(object, id=id)
        mat[,names(coefi)]%*%coefi
}
```

k-fold Cross Validataion Method
-------------------------------
Divide the dataset into k-fold: (k-1) as training and k as testing dataset

```{r}
set.seed(11)
folds <- sample(rep(1:10, length=nrow(Hitters)))
folds
table(folds)
cv.errors <- matrix(NA, 10, 19)
for (k in 1:10){
        best.fit <-regsubsets(Salary~., data=Hitters[folds!=k,], nvmax=19, method="forward")
        for (i in 1:19){
                pred <- predict(best.fit, Hitters[folds==k,], id=i)
                cv.errors[k,i] <- mean((Hitters$Salary[folds==k]-pred)^2)
        }
}
rsme.cv <- sqrt(apply(cv.errors, 2, mean))
plot(rsme.cv, pch=19, type="b")
```

Ridge Regression and Lasso
--------------------------
The package used is glmnet, which does not use the model formula language, so
we have to create x and y as predictors and respones
```{r}
library(glmnet)
x <- model.matrix(Salary~.-1, data=Hitters)
y <- Hitters$Salary
```

Using the function glmnet with option alpha = 0 to apply ridge regression. The
function cv.glmnet will do the cross valadation (defualt k=10)

```{r}
fit.ridge <- glmnet(x,y,alpha=0)
plot(fit.ridge, xvar="lambda", label=TRUE)
cv.ridge <- cv.glmnet(x,y,alpha=0)
plot(cv.ridge)
```

Now using Lasso within the glmnet function with alpha = 1

```{r}
fit.lasso <- glmnet(x,y,alpha=1)
plot(fit.lasso, xvar="lambda", lablel=TRUE)
cv.lasso <- cv.glmnet(x,y,alpha=1)
(cv.lasso) ; names(cv.lasso)
plot(cv.lasso)
coef(cv.lasso)
?cv.glmnet
```

Now manually select lambda using training dataset

```{r}
lasso.tr <- glmnet(x[train,], y[train], alpha=1)
lasso.tr
pred <- predict(lasso.tr,x[-train,])
dim(pred)
rsme <- sqrt(apply((pred-y[-train])^2,2,mean))
rsme
plot(log(lasso.tr$lambda), rsme, type="b", xlab="Log(Lmbda)")
lam.best <- lasso.tr$lambda[order(rsme)[1]] ; lam.best
coef(lasso.tr, s=lam.best)
```